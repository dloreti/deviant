% !TEX root = ../deviant-tkde.tex

\section{The approach}
\label{sec:approach}

\nd aims to extract a model which correctly classifies the log traces by accepting all cases in $L^+$ and rejecting those in $L^-$\footnote{The conditions on accepting all the positives and none of the negatives can be relaxed by requiring only a percentage of them.}. Besides that, it is required to perform an abstraction step in order to be able to classify also unknown traces, which are not in the input log. %Generalisation is the measure of how much tolerant or restricting the model is w.r.t unknown traces. 

\subsection{Definitions}
Before introducing our approach, we hereby provide some preliminary definitions that are relevant for the following explanation.


%%% paragrafo rimosso perche' seguendo il suggerimento di MArcoM, ho messo una quasi-formale definizione di conformance nella sezione background.
%%% \paragraph{Trace compliance} The role of \emph{compliance} of a trace w.r.t.\ a set of Declare constraints is pivotal in our approach. We assume the standard Declare semantics as detailed in~\cite{2008-Pesic}.  Given a trace $t\in A^*$ and a set of constraints $M\subseteq D[A]$, in the following we will use the notation $t\models M$ to indicate that none of the constraints in $M$ are violated in $t$. Such a notation is inspired by the \ac{LTL} semantics given in \cite{DBLP:series/lnbip/Montali10}.

%The role of \emph{compliance} of a trace w.r.t.\ a set of Declare constraints is pivotal in our approach. We assume the standard Declare semantics as detailed in~\cite{2008-Pesic}. 
%\theoremstyle{definition}
%\begin{definition}{\emph{Trace compliance.}} Given a trace $t\in A^*$ and a set of constraints $M\subseteq D[A]$, in the following we will use the notation $t\models M$ to indicate that none of the constraints in $M$ are violated in $t$.
%\end{definition}

\paragrafo{Model generality.} The notion of a model accepting a trace, often referred as the compliance of a trace w.r.t. the model, naturally introduces the relation of \emph{generality} (or the converse \emph{specificity}) between models.
%
Intuitively, a model $M$ is more general than another $M'$ if $M$ accepts a superset of the traces accepted by $M'$. That is, denoting with $T_M$ the set of all traces compliant with a model $M$, $M$ is more general than another model $M'$---and symmetrically $M'$ is more specific than $M$---if and only if $T_{M'} \subseteq T_M$. 
%
More precisely, we say that 
\theoremstyle{definition}\label{def:generality}
\begin{definition}{}
a model $M\subseteq D[A]$ is \emph{more general} than $M'\subseteq D[A]$ (written as $M \succeq M'$) when for any $t\in A^*$, $t\models M' \Rightarrow t\models M$ , and \emph{strictly more general} (written as $M \succ M'$) if $M$ is more general than $M'$ and there exists a $t'\in A^*$ s.t.\ $t'\not\models M'$ and $t'\models M$.
\end{definition}

Note that this definition is consistent with that of subsumption between Declare templates provided in Di Ciccio et al. \cite{2017-DiCiccio}. Indeed, Declare templates can be organised into a subsumption hierarchy according to the logical implications that can be derived from their semantics.
%
%\theoremstyle{plain}
\begin{example}{}
The constraint $\mathsf{INIT(a)}$ accepts only traces that start with $\mathsf{a}$. Hence, $\mathsf{a}$ exists in each one of those accepted traces. In other words, all those traces satisfy also the constraint $\mathsf{EXISTENCE(a)}$. However, the latter constraint accepts also traces that contains $\mathsf{a}$ even if they do not start with $\mathsf{a}$. This relation is valid irrespectively of the involved activity. In a sense, we could say that the template $\mathsf{EXISTENCE(X)}$ is \emph{more general} than $\mathsf{INIT(X)}$.
\end{example}
This idea is frequently expressed through the subsumption operator $\sqsupseteq$. Given two templates $d, d' \in D$, we say that $d$ \emph{subsumes} $d'$, i.e. $d$ \emph{is more general than} $d'$ (written $d\sqsupseteq d'$), if for any grounding of the involved parameters w.r.t. the activities in $A$, whenever a trace $t \in A^*$ is compliant with $d'$, it is also compliant with $d$ \cite{2017-DiCiccio} .


% \theoremstyle{definition}
\begin{remark}{}\label{re:subset-generality}
For any pair of models $M, M'\subseteq D[A]$, $M\subseteq M'$ implies that $M$ is more general than $M'$ ($M\succeq M'$). This stems from the Declare semantics \cite{2008-Pesic} on $LTL_f$ \cite{DBLP:conf/ijcai/GiacomoV13}.
\end{remark} 
%\todo[inline]{ST: I don't think the proof works, theorem is true because of Declare monotonicity, which is not mentioned in the proof. Probably not worth a theorem but needs a reference for Declare monotonicity.}
%%% Proof rimossa dopo commento di MarcoM, e sostituica con un riferimento diretto alla semantica.
%%%\begin{proof}
%%%A Declare model is a conjunction of constraints, each imposing some restrictions on the set of allowed traces. Consider two sets fulfilling the premise $M\subseteq M'$ such that $M=\{c_1,...c_m\}$ and $M'=\{c_1,...c_m, c_{m'}\}$. There are two possible cases: either the additional $c_{m'}$ in $M'$ excludes other traces w.r.t. $\{c_1,...c_m\}$---i.e. $M \succ M'$---or it does not because the traces $c_{m'}$ rules out are already disallowed by $\{c_1,...c_m\}$. $M\succeq M'$ follows.
%%%\end{proof}

Unfortunately, the opposite implication does not hold, i.e. if we have $M, M'\subseteq D[A]$ such that $M\succeq M'$, we cannot guarantee that $M\subseteq M'$. A clear example is $M=\{\mathsf{EXISTENCE(a)}\}$ and $M'=\{\mathsf{INIT(a)}\}$.

%\tododl{esempio per chiarire meglio}.
%a model $M\subseteq D[A]$ is \emph{more general} than $M'\subseteq D[A]$ when for any $t\in A^*$, $t\models M' \Rightarrow t\models M$ (written as $M' \preceq M$ ), and \emph{strictly} more general if there is a $t'\in A^*$ s.t.\ $t'\not\models M'$ and $t'\models M$ (written as $M' \prec M$).

%The notion of compliance naturally introduces the relation of \emph{generality} (or the converse \emph{specificity}) between models.
%Intuitively, a model $M$ is more general than another $M'$ if $M$ allows a superset of the traces accepted by $M'$. That is, defining $\mathcal{C}_M$ the set of all traces compliant with a model $M$, $M$ is more general than another model $M'$---and symmetrically $M'$ is more specific than $M$---if and only if $\mathcal{C}_{M'} \subset \mathcal{C}_M$; or more precisely,
%\theoremstyle{definition}
%\begin{definition}{\emph{Model generality/specificity}.}
%We say that a model $M\subseteq D[A]$ is \emph{more general} than $M'\subseteq D[A]$ when for any $t\in A^*$, $t\models M' \Rightarrow t\models M$ (written as $M' \preceq M$ ), and \emph{strictly} more general if there is a $t'\in A^*$ s.t.\ $t'\not\models M'$ and $t'\models M$ (written as $M' \prec M$).
%\end{definition}


%\tcolor{red}{**********
%
%Obviously, testing the generality of a model according to this definition is not feasible, because it requires considering all the allowed/disallowed traces. The closure operator can be employed for such purpose. The two methods---comparing the set of traces $\mathcal{C}_M$ and $\mathcal{C}_{M'}$, or comparing their closures ${cl}(M)$ and ${cl}(M')$---are not equivalent because the deductive system deriving from the Declare language is not complete. 
%Nonetheless, as the system is correct, the closure operator can be used to identify which model is more general/specific.}

%\paragraph{Generality of models} The notion of compliance naturally introduces the relation of \emph{generality} (or the converse specificity) between models. We say that a model $M\subseteq D[A]$ is \emph{more general} than $M'\subseteq D[a]$ when for any $t\in A^*$, $t\models M' \Rightarrow t\models M$ (written as $M' \preceq M$ ), and \emph{strictly} more general if there is a $t'\in A^*$ s.t.\ $t'\not\models M'$ and $t'\models M$ (written as $M' \prec M$).

%In general, the goal of our technique is to select one, or more, sets of Declare constraints such that all positive traces and none of the negative are compliant.\footnote{The conditions on all the positives and none of the negatives can be relaxed requiring a percentage of them; but this is outside the focus of the present work, and left for future investigation}



\paragrafo{Initial model} A wide body of research has been devoted to techniques to mine declarative process models that characterise a given event log (our positive traces). Our approach can leverage these techniques and refine their results by taking into account the negative examples as well. To this end, we consider a---possibly empty---\emph{initial model} $P$, i.e. a set of Declare constraints that are known to characterise the positive traces. For example, such set can be the expression of domain knowledge or the result of a state-of-the-art discovery algorithm previously applied to $L^+$. To apply our technique we only require that all the positive traces are compliant with all the constraints in $P$. 
We are aware that often state-of-the-art approaches do not emit a model compliant with all the traces in the input log. In these cases, we consider as positive only the traces that are allowed by $P$.
%We are aware of the fact that often this is not guaranteed by state-of-the-art approaches; in these cases we assume that the positive traces are a subset $L'^+$ of the original $L^+$ including only the traces compliant with $P$; i.e.\ $L'^+ = \{ t\in L^+\mid t\models P\}$.
%ho tolto questa formulazione perchï¿½ non mi sembra conforme alle definizioni precedenti. Noi abbiamo detto che assumiamo che l'input event log contenga L+ e L- e abbiamo definito L+ come il subset delle positive in input (non come l'event log completo).



\paragrafo{Candidate solution} As the goal of our technique is to refine the initial model $P$ taking into account both positive and negative traces, we can define which are the necessary conditions for a set of constraints $S$ to be a candidate solution for our discovery task.

\theoremstyle{definition}
\begin{definition}{}\label{def:cand}
Given the initial model $P$, a \emph{candidate solution} for the discovery task is any $S\subseteq D[A]$ s.t.
\begin{enumerate} [label=\textit{(\roman*)}]
  \item $P\subseteq S$;
  \item $\forall t\in L^+$ we have $t\models S$;\label{def:cand:sound}
  \item $\forall t\in L^-$ we have $t\not\models S$.
\end{enumerate}
\end{definition}
%\todo[inline]{ST: the third condition is too restrictive, since prevents solutions that exclude only part of $L^-$, also when this is due to the language bias induced by $L^+$. Possible solutions: i) drop it (doesn't make much sense); ii) substitute $L^-$ with the subset of traces that can be excluded by the language bias induced by $L^+$; iii) any other?

%One way of doing (ii) is to define $D[A]_{L^+} = \{ c \in D[A] \mid \forall t\in L^+$ $t\models c\}$ (the \emph{compatibles}) and $L'^- = \{t\in L^-\mid t\not\models D[A]_{L^+}\}$}

Note that condition~\ref{def:cand:sound} in the definition above ensures that any candidate solution is consistent (i.e., there are no conflicting constraints) when ${L^+}$ is non-empty.

\paragrafo{Optimality criterion} Clearly, there can be several sets satisfying these conditions. They differ from the way they classify the unknown traces, which are not in $L^+$, nor in $L^-$. Therefore, we need to introduce some way to compare the multiple output models in order to identify the preferable ones.
%Clearly, there can be several sets satisfying these conditions and we need to introduce a notion of \emph{fitness} to identify the preferred ones. 
%
In some context, \emph{generality} can be a measure of the quality of the solution, i.e. we want to identify the set that is less committing in terms of restricting the admitted traces. In some other context on the contrary, we might be interested in the identification of a more specific model. So besides allowing all traces in $L^+$ and forbidding all traces in $L^-$, the choice between a general or specific model, obviously affects the classification of the unknown traces. Alternatively, \emph{simplicity} is another criterion: one can be interested in the most \emph{simple} solution, i.e. the one that is presumed to be easier to understand irrespectively from the degree of generality/specificity it accomplishes.

%\tcolor{red}{*************************}

Let us focus on \emph{generality} for the moment. In this case, we are interested in the candidate solution $S$ (i.e., satisfying the properties of Definition \ref{def:cand}) such that there is no other candidate solution $S'\subseteq D[A]$  strictly more general than $S$ (i.e., $\nexists~ S'$ s.t. $S\prec S'$).
%If we consider generality as the fitness measure then we focus on the minimal sets $S$ satisfying the above properties and s.t.\ there is no $S'\subseteq D[A]$ satisfying the properties and strictly more general than $S$ (that is $S\prec S'$).


Although testing for strict generality between two set of constraints is a decidable problem, its worst case complexity makes an exact algorithm unfeasible because, recalling definition \ref{def:generality}, it would require to asses the compliance of any trace $t \in A^*$ with the two models going to be compared.
For this reason, we propose an alternative method based on comparing the logical consequences that can be deducted from the models.

The method makes use of a set of deduction rules which account for the \emph{subsumption} between Declare templates. Our work integrates the rules introduced in \cite{2017-DiCiccio}, into a function, namely the \emph{deductive closure operator}, which satisfies the properties of extensivity, monotonicity, and idempotence.


\theoremstyle{definition}\label{def:closure}
\begin{definition}{}
Given a set $R$ of subsumption rules, a \emph{deductive closure operator} is a function $cl_R: \mathcal{P}(D[A])\rightarrow\mathcal{P}(D[A])$ that associates any set $M \in D[A]$ with all the constraints that can be logically derived from $M$ by applying one or more deduction rules in $R$.
\end{definition}

\begin{example}
Let be:
\begin{itemize}
\item $R=\{\ \mathsf{EXISTENCE(X)} \sqsupseteq \mathsf{INIT(X)}\ \}$
\item $M'=\{ \mathsf{INIT(a)}\ \}$
\end{itemize}
If we apply the deductive closure operator $cl_R$ to $M'$, we get:
$$
cl_R(M') = \{\ \mathsf{INIT(a), EXISTENCE(a)}\ \}
$$
\end{example}

\noindent Obviously, we are interested in sets $R$ of \emph{correct} subsumption rules, that is for any $M\subseteq D[A]$ and $t\in A^*$, $t\models M$ iff $t\models cl_R(M)$. In the rest of the paper, for the easy of understanding, we will omit the set $R$ and we will simply write $cl(M)$. The complete set of employed rules is available in~\cite{negdis:2021_5158528}.


As the closure of a model is again a subset of $D[A]$, Remark \ref{re:subset-generality} is also applicable, i.e. for any $M, M'\subseteq D[A]$, $cl(M)\subseteq cl(M')$ implies that $M$ is more general than $M'$ ($M\succeq M'$).
%
%Because of the ``correctness'' of the $cl$ operator, we can guarantee the following lemma.
%\theoremstyle{definition}\label{lemma:closure-generality}
%\begin{lemma}{}
%For any pair of sets $M, M'\subseteq D[A]$, $cl(M)\subseteq M'$\tododl{$cl(M)\subseteq cl(M')$} implies that $M$ is more general than $M'$ ($M'\preceq M$).
%\end{lemma} 
%
%\begin{proof}
%\tcolor{red}{Proof TODO}
%\end{proof}
Thanks to this property, the deductive closure operator can be used to compare Declare models w.r.t.~generality. To provide an intuition, let us consider the following example:

\begin{example}
Let be:
\begin{itemize}
\item $R=\{\ \mathsf{EXISTENCE(X)} \sqsupseteq \mathsf{INIT(X)}\ \}$
\item $M = \{\ \mathsf{EXISTENCE(a)}\ \}$
\item $M' = \{\ \mathsf{INIT(a)}\ \}$
\end{itemize}
We cannot express any subset relation between $M$ and $M'$, thus making Remark \ref{re:subset-generality} inapplicable.
Nonetheless, if we take into account their closure, we have:
\begin{align*}
	& cl(M)=\{\mathsf{EXISTENCE(a)}\}\quad \textnormal{and} \\
	& cl(M')=\{\mathsf{INIT(a)}, \mathsf{EXISTENCE(a)}\}
\end{align*}
As $cl(M)$ is a subset of $cl(M')$, we conclude that $M$ is more general than $M'$.
\end{example}
%
\noindent In other words, the closure operator (being based on the subsumption rules) captures the logical consequences deriving from the Declare semantics.
Due to the nature of the Declare language we cannot provide a complete calculus for the language of conjunctions of Declare constraints. For this reason, we cannot guarantee the strictness, nor the opposite implication (i.e. $M'\preceq M$ does not implies $cl(M)\subseteq cl(M')$). Anyway, the closure operator provide us a powerful tool for confronting candidate solutions w.r.t. the generality criterion.


%To provide an intuition let us consider two possible candidates $S' = \{\mathsf{INIT(a)}\}$ and $S = \{\mathsf{EXISTENCE(a)}\}$. It's easy to see that any trace compliant with $\mathsf{INIT(a)}$ must be compliant also with $\mathsf{EXISTENCE(a)}$, therefore $\{\mathsf{INIT(a), EXISTENCE(a)}\}$ is equivalent to $S'$. If we compare the deductive closure of the two sets we can conclude that $S$ is more general that $S'$.\footnote{Not necessarily \emph{strictly} more general.}


%To built the closure operator, this work integrates the deduction rules introduced in various articles \cite{2017-DiCiccio,???}\tododl{x sergio, quali altri paper?}. The resulting operator also satisfies the properties of extensivity, monotonicity, and idempotence. The complete set of rules employed is available at \cite{?}. 

%Unfortunately, we cannot guarantee neither the other way around, nor the strictness\tododl{forse va spiegato con pi\`u dettagli il perche non possiamo?}. However, the use of specific classes of operators enable the use of off the shelf finite domain optimisers, as we will show in the following section. 

%Unfortunately, due to the nature of the Declare language we cannot provide a complete calculus\todo{Here we need more details}, therefore we will resort to a set of \emph{correct} deduction rules; e.g.\ the rules introduced in~\cite{???} \tododl{da quale paper le abbiamo prese. Se sono state estese dovremmo spiegare come}. To this end we introduce the notion of a (correct) deductive closure operator\todo{ST: I don't know whether it'a a good name}~for the Declare language.

%\paragraph{Closure operator} In this context a \emph{deductive closure operator} is a function $cl: \mathcal{P}(D[A])\rightarrow\mathcal{P}(D[A])$ satisfying the properties of extensivity, monotonicity, and idempotence; moreover it should be ``correct'' w.r.t.\ deduction in Declare, that is for any $C\subseteq D[A]$ and $t\in A^*$, $t\models C$ iff $t\models cl(C)$.

%Because of the ``correctness'' requirement of $cl$ we can guarantee that for any pair of sets $C, C'\subseteq D[A]$, $cl(C)\subseteq C'$ implies that $C$ is more general than $C'$ ($C'\preceq C$). Unfortunately, we cannot guarantee neither the other way around, nor the strictness\tododl{forse va spiegato con pi\`u dettagli il perche non possiamo?}. However, the use of specific classes of operators enable the use of off the shelf finite domain optimisers, as we will show in the following section. 









\subsection{Two-step procedure}

In this section we introduce the theoretical basis of our \nd approach. The parameters of the problem are the following.
\begin{itemize}
  \item $D$ set of Declare templates (language bias)
  \item $A$ set of activities
  \item $cl$ closure operator equipped with a set $R$ of subsumption rules. $cl: \mathcal{P}(D[A])\rightarrow\mathcal{P}(D[A])$
  \item $L^+$ log traces labelled as positive. $L^+ \subseteq A^*$
  \item $L^-$ log traces labelled as negative. $L^- \subseteq A^*$
  \item $P$ initial model. $P\subseteq \{c\in D[A]\quad | \quad \forall t\in L^+,\, t\models c\}$
\end{itemize}

For the sake of modularity and easiness of experimenting with different hypotheses and parameters, we divide our approach into two clearly separate stages: the first which identifies the candidate constraints, and a second optimisation stage which selects the solutions. However, these two steps are merged into a single monolithic search-based approach. 

Starting from the set of all constraints $D[A]$, the first stage aims at identifying all the constraints of $D[A]$ which accept all positive traces and reject at least a negative one. To this end, it first computes the set of constraints that accepts all traces in $L^+$, namely the set \emph{compatibles}. 
\begin{equation}
{compatibles(D[A], L^+)} = \{c\in D[A]~|~\forall t\in L^+,~ t\models c \} \\
\end{equation}
%
By construction, any subset of ${compatibles(D[A], L^+)}$ is non-conflicting, because any trace in ${L^+}$ is accepted by all its constraints. This simplifies the optimisation step, since there is no need to verify whether any of the selected models are conflicting (see point~\ref{def:cand:sound} of Definition~\ref{def:cand}).

For simplicity of the notation, since the set of constraints $D[A]$ and the log $L^+$ are given, we will omit them in the following.
%
The \emph{compatibles} set is then used to build a \textit{\sheriff} function that associates to any trace $t$ in $L^-$ the constraints of \textit{compatibles} that rejects $t$. 
The result is therefore a function with domain $L^-$ and co-domain $\mathcal{P}({compatibles})$ s.t.:
\begin{equation}
{\textit{\sheriff}}(t) = \{c\in {compatibles}~|~t\not\models c\} \\
\end{equation}



The second stage aims at finding the optimal solution according to some criterion. Therefore, it starts by computing two sets $\mathcal{C}$ and $\mathcal{Z}$. 
%
Let $\mathcal{C}$ be the set of those constraints in $D[A]$ that accept all positive traces and reject at least one negative trace. Such set can be derived from the \textit{\sheriff} function as: $\mathcal{C} = \bigcup_{t\in L^-} \textit{\sheriff}(t)$.
%%
Let $\mathcal{Z}$ be all the subsets of $\mathcal{C}$ excluding all negative traces\footnote{As we will discuss in section \ref{subsec:impl}, the implementation must take into account that it might not be always possible to find models fulfilling Eq.\ref{eq:mathcalS}}, i.e.,
\begin{equation}\label{eq:mathcalS}
\mathcal{Z}=\{M\in\mathcal{P}(\mathcal{C})\mid \forall t\in L^-~t\not\models M \} 
\end{equation}

\begin{example}
Let $L^+=\{\mathsf{ab}\}$, $L^-=\{\mathsf{a, b, ba}\}$, and $D=\{\mathsf{EXISTENCE(X)},\mathsf{RESPONSE(Y,Z)}\}$.
%
The set of activities is $A=\{\ \mathsf{a}, \mathsf{b}\ \}$.
The grounded set of constraints is then $D[A] = \{$ $\mathsf{EXISTENCE(a)}$, $\mathsf{EXISTENCE(b)}$, $\mathsf{RESPONSE(a,b)}$, $\mathsf{RESPONSE(b,a)}\ \}$.

The \textit{compatibles} set would be:
\begin{align*}
compatibles(D[A], L^+) =  \{\ & \mathsf{EXISTENCE(a)},\ \mathsf{EXISTENCE(b)},\\
&  \mathsf{RESPONSE(a,b)} \ \}	
\end{align*}
%
and the computation of the \textit{\sheriff} function finds:
\begin{subequations}
 \begin{align*}
     &\textit{\sheriff}(\mathsf{a}) =\{\mathsf{EXISTENCE(b)},\ \mathsf{RESPONSE(a,b)}\} \\
     &\textit{\sheriff}(\mathsf{b}) =\{\mathsf{EXISTENCE(a)}\} \\
     &\textit{sheriff}(\mathsf{ba})=\{\mathsf{RESPONSE(a,b)}\}
 \end{align*}
%
\end{subequations}
In this case, there are two subsets of $\mathcal{C}$ excluding all traces in $L^-$, i.e., $\mathcal{Z}=\{M_1,M_2\}$, where
\begin{subequations}
 \begin{align*}
     & M_1=\{\mathsf{EXISTENCE(b)},\ \mathsf{EXISTENCE(a)},\ \mathsf{RESPONSE(a,b)}\} \\
     & M_2=\{\ \mathsf{RESPONSE(a,b)},\ \mathsf{EXISTENCE(a)}\ \}
 \end{align*}
\end{subequations}
\end{example}


%
%Note that we cannot guarantee that all negative traces can be excluded by at least one of the constraints in ${compatibles}$; i.e.\ ${choices}(t)$ might be empty for some $t\in L^-$. Therefore let $\mathcal{S}$ be all the subsets of $\mathcal{C}$ that exclude all the negative traces that can be excluded by the ${compatibles}$ (i.e.\ $\{t\in L-\mid {choices}(t)\neq \varnothing\}$). $\mathcal{S}$ can be again computed employing the $choice$ function as follows. 
%\begin{equation}
%\mathcal{S}=\{M\in\mathcal{P}(\mathcal{C})\mid \forall t\in L^-~\text{s.t.}~{choices}(t)\neq \varnothing,~ cl(M\cup P)\cap {choices}(t)\neq \varnothing\} \label{eq:mathcalS}
%\end{equation}

%This formula ensures that any model $M$ in $\mathcal{S}$ is such that the logical consequences of $M \cup P$ include the constraints to disallow the negative traces than can be excluded. In this way, any element of $\mathcal{S}$ will be a model whose constraints can be used to integrate the initial model $P$ with further information about the negative traces. As any $M \in \mathcal{S}$ fulfil all the properties of Definition \ref{def:cand}, it is a \emph{candidate solution} for our discovery task.

%The reason why the deductive closure operator is employed in Eq. \ref{eq:mathcalS} can be highlighted through a simple example. Consider the set of negative traces $L^-=\{\mathsf{b, ab, a}\}$ and suppose the computation of the ${choice}$ function has found three constraints $choice(\mathsf{b})=\{\mathsf{EXISTENCE(a)}\}$, $choice(\mathsf{ba})=\{\mathsf{RESPONSE(a,b)}\}$, and $choice(\mathsf{a})=\{\mathsf{EXISTENCE(b)}\}$. Apparently, the only way to exclude all traces in $L^-$ is to emit a model $M_1=\{$\textsf{EXISTENCE(a), RESPONSE(a,b), EXISTENCE(b)}$\}$. Nonetheless, as 
%$\mathsf{EXISTENCE(b)} \sqsupseteq \mathsf{EXISTENCE(a)} \land  \mathsf{RESPONSE(a,b)}$, 
%taking into account the closure in Eq. \ref{eq:mathcalS} allows emitting another candidate solution $M_2=\{\mathsf{EXISTENCE(a), RESPONSE(a,b)}\}$

Once $\mathcal{C}$ and $\mathcal{Z}$ are computed, the goal of the optimisation step is to select the ``best'' model in $\mathcal{Z}$ which can be either devoted to \emph{generality/specificity}, or \emph{simplicity}.
When the most general model is desired, the procedure selects as solution the model $S\in \mathcal{Z}$ such that 
\begin{subequations}
  \begin{align}
    \text{there is no $S'\in\mathcal{Z}$ s.t. } cl(S'\cup P)\subset cl(S\cup P) \label{eq:most-gen}\\
    \text{there is no $S'\subset S$ s.t. } cl(S'\cup P)=cl(S\cup P)\label{eq:redun}
  \end{align}
\end{subequations}
%
The first condition, Eq. \eqref{eq:most-gen}, ensures generality by selecting the model $S$ for which the logical consequences of $S\cup P$ are the less restricting. 
In this way, the initial model $P$ (containing a set of Declare constraints that are known to characterise $L^+$) is enriched taking into account the information derived by $L^-$.
%Furthermore, the closure operator $cl$ is crucial because from the point of view of generality we are not interested in the content of the selected model, but rather in its logical consequences. 
Furthermore, since from the point of view of generality we are not interested in the content of the selected model, but rather in its logical consequences, the closure operator $cl$ ensures that no other model in $\mathcal{Z}$ is more general than the chosen $S$. 
%
The second condition, Eq. \eqref{eq:redun}, allows to exclude redundancy inside the selected model $S$ by ensuring that it does not contain constraints that are logical consequence of others in $S$. Considering the previous example, this optimisation step allows to chose model $M_2$ as solution because $\mathsf{EXISTENCE(b)}$ is a logical consequence of $\mathsf{EXISTENCE(a)} \land  \mathsf{RESPONSE(a,b)}$.

If we were interested in the less general model, condition \eqref{eq:most-gen} would be 
\begin{equation}\label{eq:most-spe}
\text{there is no $S'\in\mathcal{Z}$ s.t. } cl(S'\cup P)\supset cl(S\cup P)
\end{equation}
whereas the redundancy constraint would be ensured through the same Eq. \eqref{eq:redun} because, even when we look for the most specific model, redundancy compromises its readability, without adding any value.

Generality/specificity is not the only desirable optimality criterion. If we are interested in the \emph{simplest} model instead, a solution composed of a limited number of constraints is certainly preferable. So, we also experimented with an alternative optimisation formulation based on the set cardinality. The procedure selects the $S \in\mathcal{Z}$ such that:
\begin{subequations}
   \begin{align}
    \text{there is no } S'\in\mathcal{Z} \text{ s.t. } & |cl(S'\cup P)| < |cl(S\cup P)| \label{eq:simpl1}\\
	\begin{split}
    \text{there is no } S'\in\mathcal{Z} \text{ s.t. } & |cl(S'\cup P)|=|cl(S\cup P)| \text{ and}\\
	&  |S'| < |S| \label{eq:simpl2} 
	\end{split}
   \end{align}
\end{subequations}
where the first equation selects the set with the smaller closure, whereas the second allows to choose the solution with less constraints among those with closure of equal cardinality.%\tododl{con un esempio diverso sarebbe bello mostrare risultati diversi quando cerchiamo il modello pi\`u specifico e quello pi\`u semplice}

%We also experimented with an alternative optimisation formulation taking into account cardinality instead of subset relation. The idea is to select the ``minimum causes'' for the rejection of all negative traces. This formulation can be expressed by the properties:
%\begin{subequations}
%  \begin{align}
%    \text{there's no $S'\in\mathcal{S}$ s.t. } |cl(S'\cup P)| < |cl(S\cup P)|\\
%    \text{there's no $S'\in\mathcal{S}$ s.t. } |cl(S'\cup P)|=|cl(S\cup P)| \text{ and } |S'| < |S|
%  \end{align}
%\end{subequations}

\theoremstyle{definition}\label{th:subset-generality}
\begin{theorem}{}
The models that are solution according to the simplicity criterion are also solutions for the generality criterion.
\end{theorem} 
\begin{proof}
Suppose ad absurdum that there is a model $S\in\mathcal{Z}$ that is optimal according to the simplicity criterion of Eq.~\eqref{eq:simpl1} and \eqref{eq:simpl2} but it is not the most general, i.e. either Eq.~\eqref{eq:most-gen} or Eq.~\eqref{eq:redun} are violated for $S$. If $S$ violated Eq.~\eqref{eq:most-gen}, it would exists an $S'\in\mathcal{Z}$ s.t. $cl(S'\cup P)\subset cl(S\cup P)$. But clearly, this implies that $|cl(S'\cup P)| < |cl(S\cup P)|$, which contradicts Eq.~\eqref{eq:simpl1}. On the other hand, if $S$ violated Eq.~\eqref{eq:redun}, it would exists an $S' \subset S$ s.t. $cl(S'\cup P)=cl(S\cup P)$. Obviously we would also have $|S'| < |S|$ and $|cl(S'\cup P)|=|cl(S\cup P)|$, which contradict Eq.~\eqref{eq:simpl2}. 
\end{proof}

Conversely, the opposite implication in Theorem \ref{th:subset-generality} does not necessarily hold. Indeed, let assume that $P$ is empty and $cl$ is the identity function\footnote{This may also be the case when the constraints selected in the first stage are logically independent.}; consider two negative traces $t_1, t_2$ and a \textit{\sheriff} function producing three constraints $\{c_1, c_2,c_3\}$. In particular, $\textit{\sheriff}(t_1)=\{c_1, c_2\}$ and $\textit{\sheriff}(t_2)=\{c_1, c_3\}$. The only simplicity-oriented solution would be  $\{c_1\}$, whereas as regards the generality-oriented solutions we would have both $\{c_1\}, \{c_2, c_3\}$. We must remark that the simplicity principle is based on the intuition that ``smaller'' Declare models should be easier to understand for humans. However, we might notice that, since the two models $\{c_1\}$ and $\{c_2, c_3\}$ are not directly comparable according to their semantics, deciding which is the ``best'' might depend on the constraints themselves, ad well as the specific domain.




%e' vero che la cardinalitï¿½ sceglie c1 e questo ha senso se pensiamo che spesso si vuole il set piï¿½ piccolo di vincoli perchï¿½ cosï¿½ il modello risulta piï¿½ complensibile. However, questo potrebbe non essere sempre preferibile: la subset-based non getta via c1,c3 perchï¿½ di fatto se le chiusure sono diverse non ï¿½ detto che c1 sia preferibile. magari in quello specifico dominio ha piï¿½ senso c1,c3
%\tcolor{blue}{The cardinality-based solution, which could be driven by the simplicity principle, is based on the intuition that "smaller" Declare models are easier to be understood by humans. However, we might notice that {c1} and {c2,c3} are not directly comprable, since their meaning (and their understandability too) might depend by the constraints, ad well as by the domain semantics.}

\subsection{Implementation}
\label{subsec:impl}
%To perform our experiments we decided to separate the implementation of the two stages by reusing as much as possible existing systems.

The first stage is implemented via the Algorithm \ref{algcand}, which starts by collecting the set $compatibles$ of the constraints that accept (are satisfied by) all the positive traces (Line \ref{algcand:candidates}). Subsequently, each negative trace is associated (by means of the function \textit{\sheriff}) with those constraints in $compatibles$ that reject (are violated by) a trace in $L^-$ (Line \ref{algcand:choices}). Notice that for some negative example, i.e. for some trace $t\in L^-$ we might have $\textit{\sheriff}(t)=\varnothing$ because the chosen language may not be expressive enough to find a constraint able to reject $t$ while admitting all traces of $L^+$. This situation might arise also in case $t$ belongs to both $L^+$ and $L^-$.
%

\makeatletter
\algrenewcommand\ALG@beginalgorithmic{\footnotesize}
\makeatother

\begin{algorithm}
    \caption{Identification of the constraints accepting all traces in $L^+$ and rejecting at least one trace in $L^-$.}
    \label{algcand}
    \textbf{Input:}  $D[A], L^+, L^-$\\
    \textbf{Output:} $\textit{\sheriff} : L^- \rightarrow \mathcal{P}({D[A]})$
    	\begin{algorithmic}[1] 
   \Procedure{\sheriff Generation}{$D[A],\, L^+,\, L^-$} 
   	\State ${compatibles}{=}\{c \in D[A]| \forall t \in L^+,\, \Call{compliant}{t,c} = \texttt{True}\}$ 
	\label{algcand:candidates}
	\For {$t \in L^-$}
		\State $\textit{\sheriff}(t){=}\{c \in {compatibles} | \Call{compliant}{t,c} = \texttt{False}\}$\label{algcand:choices}
	\EndFor
	%\State \Return ${compatibles}, {choices}$
	\State \Return \textit{\sheriff}
    \EndProcedure
    \end{algorithmic}
\end{algorithm}

\makeatletter
\algrenewcommand\ALG@beginalgorithmic{\normalsize}
\makeatother

The implementation of the compliance verification \textproc{compliant} (i.e.\ $t\models c$) leverages the semantics of Declare patterns defined by means of regular expressions \cite{2017-DiCiccio}%\tododl{x sergio, hai aggiunto altre regexp oltre a quelle del paper di Di Ciccio?}
~to verify the compliance of the traces. It is implemented in Go language employing a regexp implementation that is guaranteed to run in time linear in the size of the input\footnote{For more details, see the Go package regexp documentation at \url{https://golang.org/pkg/regexp/}}.
\lstset{language=Prolog}

The second optimisation stage has been implemented using the \ac{ASP} system \textsc{Clingo}~\cite{clingo:2019}. The main reason for selecting an \ac{ASP} system for finite domain optimisation is that rules provide an effective and intuitive framework to implement a large class of closure operators. Indeed, all the deductive systems for Declare that we analysed in the literature (see e.g.~\cite{2016-Bernardi,2017-DiCiccio}) are expressed in the form of logic rules $c_1\land\ldots\land c_n\implies c_{n+1}$, where $c_i$ are Declare constraints or their negation; therefore they can be equivalently expressed as Normal Logic Programs~\cite{2008-Lifschitz} (NLPs) by exploiting the assumption that the set of activities is finite and known in advance. The declarative semantics of NLPs ensures that the (unique) deductive closure of the rules is taken into account for the optimisation stage.
%
For example the valid formula $\textsc{Init}(a)\land b\neq a\implies\textsc{Precedence}(a,b)$ that holds for any pair of activities $a, b$ can be written as the rule
\begin{lstlisting}[language=prolog, breaklines=true]
precedence(A,B) :- init(A), activity(B), A != B.
\end{lstlisting}
using a specific predicate (\lstinline[language=prolog]$activity/1$) representing the set of all activities.\footnote{By leveraging \textsc{Clingo} function symbols, Declare constraints are encoded as function terms; for example, the constraints derived are represented using the unary predicate \lstinline[language=prolog]$holds/1$: \lstinline[language=prolog,mathescape=true]|holds(precedence($a_1$,$a_2$))|.}

%Note that the selection of the optimal stable models does not require the compliance verification on the traces, which are therefore not necessary as input. 

The optimisation stage is described in Algorithm \ref{alg:select}. The required input parameters, properly encoded as an \ac{ASP} program, are the initial model $P$, the \textit{\sheriff} function computed by Algorithm \label{alg:cand} and a custom function ${is\_better}:\mathcal{P}({D[A]})\times\mathcal{P}({D[A]})\rightarrow \{\texttt{True},\ \texttt{False}\}$. The purpose of the latter is to implement the chosen optimality criterion by taking as input two constraint sets and providing as output a boolean value representing whether the first set is better than the second. If the two sets are not comparable according to the criterion, ${is\_better}$ returns \texttt{False}. Indeed, such a function is the expression of the global or partial ordering that the optimality criterion induces on the solutions. 


%\begin{algorithm}
%    \caption{Selection of the best solution according to custom model fitness.}
%    \label{alg:select}
%    \textbf{Input:}  ${cl}: \mathcal{P}({D[A]}) \rightarrow \mathcal{P}({D[A]}), {choices} : L^- \rightarrow \mathcal{P}({D[A]}), P$\\
%    \textbf{Output:} $S \subseteq D[A]$
%	\begin{algorithmic}[1] 
%   \Procedure{Selection}{${choices}, P$} 
%  	\State $\mathcal{C} = \bigcup_{t\in L^-} choices(t)$\label{alg:buildC}
%	\State \textbf{select} $S \subseteq \mathcal{C}$ \textbf{s.t.} \label{alg:subsetC}
%	\Indent
%		\State 1. $\forall t \in L^- \; ({choices}(t) = \varnothing \textbf{ or } {cl}(S \cup P)\cap {choices}(t) \neq \varnothing$) 	\label{alg:select:1}
%		\State 2. $is\_optimal(S)$									\label{alg:select:2}
%	\EndIndent
%	\State \Return $S$  
%    \EndProcedure
%    \end{algorithmic}
%\end{algorithm}

%\begin{algorithm}
%    \caption{Selection of the best solutions according to a custom criterion.}
%    \label{alg:select}
%    \textbf{Input:}  ${cl}: \mathcal{P}({D[A]}) \rightarrow \mathcal{P}({D[A]}), {choices} : L^- \rightarrow \mathcal{P}({D[A]}), P$\\
%    \textbf{Output:} $\mathcal{Z}$
%	\begin{algorithmic}[1] 
%   \Procedure{Selection}{${choices}, P$} 
%   	\State $\mathcal{Z}=\varnothing$
%  	\State $\mathcal{C} = \bigcup_{t\in L^-} choices(t)$\label{alg:buildC}
%	\State \textbf{for any} $S \subseteq \mathcal{C}$ \textbf{s.t.} \label{alg:subsetC}
%	\Indent
%		\State \textit{i)} $\forall t \in L^- \; \Big( {choices}(t) = \varnothing \textbf{ or } {cl}(S \cup P)\cap {choices}(t) \neq \varnothing\Big)$ 	\label{alg:select:1}
%		\State \textit{ii)} $is\_optimal(S)$									\label{alg:select:2}
%		\State \textbf{do} $\mathcal{Z}=\mathcal{Z}\cup\{S\}$
%	\EndIndent
%	\State \Return $\mathcal{Z}$  
%    \EndProcedure
%    \end{algorithmic}
%\end{algorithm}

\begin{algorithm}
    \caption{Selection of the best solutions according to a custom criterion.}
    \label{alg:select}
    \textbf{Input:}  $P,\, \textit{\sheriff} : L^- \rightarrow \mathcal{P}({D[A]})$,$\,{is\_better}:\mathcal{P}({D[A]})\times\mathcal{P}({D[A]})\rightarrow \{\texttt{T},\texttt{F}\}$\\
    \textbf{Output:} $\mathcal{Z}$, i.e. the set of the best solutions
	\begin{algorithmic}[1] 
   \Procedure{Selection}{$\textit{\sheriff},\, P$} 
   	\State $\mathcal{Z}=\varnothing$
  	\State $ L'^- = \{t \in L^- \: | \: \textit{\sheriff}(t) \neq \varnothing \land t\models P\}$
	\State $\mathcal{C} = \bigcup_{t\in L'^-} \textit{\sheriff}(t)$\label{alg:buildC}
	\State \textbf{for each} $S \subseteq \mathcal{C}$ \textbf{s.t.} $\forall t \in L'^-, \; S\cap \textit{\sheriff}(t) \neq \varnothing$ \textbf{do} \label{alg:subsetS}
	\Indent
		\If{$(\forall S'\in\mathcal{Z} \ !is\_better(S',S)\,)$} \label{alg:isbetter}
		\State $\mathcal{Z} \, \leftarrow\, \{S\} \cup \{ S'\in\mathcal{Z}\ |\ !is\_better(S,S')\,\}$ \label{alg:previousAreOk}
		\EndIf
	\EndIndent
	\State \Return $\mathcal{Z}$  
    \EndProcedure
    \end{algorithmic}
\end{algorithm}

The algorithm starts by computing a set $L'^-$ of all those negative traces that can be excluded by at least a constraint ($\textit{\sheriff}(t)\neq\varnothing$) and are still instead accepted by the initial model $P$ ($t\models P$). 
Indeed, albeit from the theoretical point of view we assumed that for each trace $t \in L^-$ there exists at least one Declare constraint in $D[A]$ accepting all positive traces and discarding $t$, real cases might not fulfil this assumption.%, and the algorithm implementation must take this into account. 
When it is not possible to exclude a negative trace $t$, Algorithm \ref{algcand} returns $\textit{\sheriff}(t)=\varnothing$, and Algorithm \ref{alg:select} overlooks this case by computing $L'^-$. 
%
The set $\mathcal{C}$ is then build (Line \ref{alg:buildC}) by considering the constraints allowing all traces in $L^+$ and disallowing at least one trace in $L'^-$ (Line \ref{alg:buildC}). From that, the algorithm selects any subset $S$ fulfilling the condition $\forall t \in L'^- \; S\cap \textit{\sheriff}(t) \neq \varnothing$ (Line \ref{alg:subsetS}), i.e., any $S$ accepting all positive traces and rejecting all the negatives that can be actually excluded.

Any such $S$ is then included in the solution set $\mathcal{Z}$ if the latter does not contain another solution $S'$ that is better than $S$ according to the custom optimality criterion expressed by the ${is\_better}$ operator (Line \ref{alg:isbetter}). Solutions $S'$ previously founded are kept into $\mathcal{Z}$ only if the newly found solution $S$ is not better than them (Line \ref{alg:previousAreOk}). Notice that both Line \ref{alg:isbetter} and \ref{alg:previousAreOk} make use of the function $is\_better$ in a negated form: this is due to the fact that, according to the chosen optimality criterion, sometimes it would not be possible to compare two solutions.

Regarding the optimality criterion, for example we could consider \emph{generality}. In that case, ${is\_better}$ employs the criteria of Eq. \eqref{eq:most-gen} (for generality) and \eqref{eq:redun} (to avoid redundancy). Conversely, if we are interested in the most specific solution, ${is\_better}$ must implement Eq. \eqref{eq:most-spe} and \eqref{eq:redun}.
Finally, when the optimality criterion is \emph{simplicity}, Eq. \eqref{eq:simpl1} and \eqref{eq:simpl2} must be used.
%
In our experiments we implemented the optimisation criteria using ASP \emph{weak constraints}~\cite{ASP:weak:2000}. Describing the underlying technique and precise formulation of the problem is outside the scope of this article; so the reader is referred to our code, available in~\cite{negdis:2021_5158528}, and~\cite{clingo:2019} for details on the usage of weak rules in \textsc{Clingo}. For example, conditions of Equations~\eqref{eq:simpl1} and \eqref{eq:simpl2} are implemented using two predicates \lstinline[language=prolog]$selected/1, holds/1$; representing, respectively, the selected constraints among the candidates and their deduction, with the optimisation statements:
\begin{lstlisting}[language=prolog]
#minimize{1@2,C: holds(C)}.
#minimize{1@1,C: selected(C)}.
\end{lstlisting}
%
The selection from the set of candidates is performed by the common \emph{generate and test} ASP paradigm:
%
\begin{lstlisting}[language=prolog]
{ selected(C) : choice(_,C) }.
\end{lstlisting}
%
where \lstinline[language=prolog]$choice/2$ is the input to the ASP program, encoding the above \textit{\sheriff} function. The \emph{test} part of the paradigm is encoded by constraints enforcing the fact that, for each negative trace, at least one of the constraints in \textit{\sheriff} belongs to the deduction; i.e.
%
\begin{lstlisting}[language=prolog]
rejected(T) :- choice(T,C), holds(C).
:- choice(T,_), not rejected(T).
\end{lstlisting}



%The algorithm starts by computing the set $\mathcal{C}$ of the constraints allowing all traces in $L^+$ and disallowing at least one trace in $L^-$ (Line \ref{alg:buildC}). From that, it selects as solution model a subset $S$ fulfilling two conditions.
%%The first condition (Line \ref{alg:select:1}) specifies that $S$ must be such that it allows all traces in $L^+$ and, whenever possible, discards all those in $L^-$. Indeed, for any negative trace $t$ the algorithms admits that either there is no way to exclude such trace ($choices(t)=\varnothing$), or it is excluded by the model $S \cup P$ (condition ${cl}(S \cup P)\cap {choices}(t) \neq \varnothing$).
%The first condition (Line \ref{alg:select:1}) specifies that $S$ must be such that it allows all traces in $L^+$ and, whenever possible, discards all those in $L^-$. Indeed, albeit from the theoretical point of view we assumed that for each trace $t \in L^-$ there exists at least one Declare constraint allowing all positive traces and discarding $t$, real cases might not fulfil this assumption, and the algorithm implementation must take it into account. To this end, condition \textit{i)} imposes that for any negative trace $t$, either there is no way to exclude such trace ($choices(t)=\varnothing$), or it is excluded by the model $S \cup P$ (condition ${cl}(S \cup P)\cap {choices}(t) \neq \varnothing$). The employment of the closure operator is necessary to to take into account all the Declare constraints that are logical consequence of $S \cup P$.
%%
%%Note that we cannot guarantee that all negative traces can be excluded by at least one of the constraints in ${compatibles}$; i.e.\ ${choices}(t)$ might be empty for some $t\in L^-$. Therefore let $\mathcal{S}$ be all the subsets of $\mathcal{C}$ that exclude all the negative traces that can be excluded by the ${compatibles}$ (i.e.\ $\{t\in L-\mid {choices}(t)\neq \varnothing\}$). $\mathcal{S}$ can be again computed employing the $choice$ function as follows. 
%%\begin{equation}
%%\mathcal{S}=\{M\in\mathcal{P}(\mathcal{C})\mid \forall t\in L^-~\text{s.t.}~{choices}(t)\neq \varnothing,~ cl(M\cup P)\cap {choices}(t)\neq \varnothing\} \label{eq:mathcalS}
%%\end{equation}
%
%%This formula ensures that any model $M$ in $\mathcal{S}$ is such that the logical consequences of $M \cup P$ include the constraints to disallow the negative traces than can be excluded. In this way, any element of $\mathcal{S}$ will be a model whose constraints can be used to integrate the initial model $P$ with further information about the negative traces. As any $M \in \mathcal{S}$ fulfil all the properties of Definition \ref{def:cand}, it is a \emph{candidate solution} for our discovery task.
%
%%The reason why the deductive closure operator is employed in Eq. \ref{eq:mathcalS} can be highlighted through a simple example.

%
%The second condition (Line \ref{alg:select:2}) accounts for an optimality criterion, which can be customised according to the specific needs. 
%%
%For example, we could consider \emph{generality} as an optimality criterion. In that case, the $is\_optimal(S)$ function implements the criteria of Eq. \eqref{eq:most-gen} (for generality) and \eqref{eq:redun} (to avoid redundancy). Conversely, if we are interested in the most specific solution, $is\_optimal(S)$ must implement Eq. \eqref{eq:most-spe} and \eqref{eq:redun}.
%Finally, when the optimality criterion is \emph{simplicity}, Eq. \eqref{eq:simpl1} and \eqref{eq:simpl2} must be used.

%Even if Algorithm \ref{alg:select} reduces the number of candidate solutions according to the condition of Line \ref{} and the optimality criterion of Line \ref{}, 
In real cases, the returned set $\mathcal{Z}$ might contain several solutions. %it is not guaranteed to return a unique solution%\tododl{in realta' l'algoritmo per come e' scritto restituisce una sola soluzione. Bisognerebbe cambiarlo per fare emergere che vengono restituite anche altre???}. 
If the number of solutions provided by the procedure is too high for human intelligibility, the optimality condition could be further refined by inducing a preference order in the returned solution. For example, among the most general solutions one can be interested in being reported first those models with the lower number of constraints, or with certain Declare templates. The advantage of our approach is precisely in the possibility to implement off-the-shelves optimisation strategies, where---adapting the $is\_better$ function or even the definition of the closure operator---the developer can easily experiment with different criteria.

%In order to better clarify the approach, we apply it to a very simple example.  
\begin{example}
Consider the sets of positive and negative examples composed by only one trace each: $L^+=\{\mathsf{bac}\}$ and $L^-=\{\mathsf{ab}\}$. Suppose also that:
\begin{itemize}
\item $P=\varnothing$;
\item $D=\{\mathsf{EXISTENCE(X), INIT(X)}\}$;
\item the alphabet of activities is just $A=\{\mathsf{a, b, c}\}$.
\end{itemize}
%
Then, the set of ground constraints can be easily elicited: $D[A]=\{\mathsf{EXISTENCE(a)}$, $\mathsf{EXISTENCE(b)}$, $\mathsf{EXISTENCE(c)}$, $\mathsf{INIT(a)}$, $\mathsf{INIT(b)}$, $\mathsf{INIT(c)}\}$.

If we want to learn the most general model, Algorithm \ref{algcand} elects the following compatible constraints:
\begin{align*}
	{compatibles}=\{ & \mathsf{EXISTENCE(a), EXISTENCE(b)},\\
	& \mathsf{EXISTENCE(c), INIT(b)}\}
\end{align*}
\noindent and emits:
$$\textit{\sheriff}(\mathsf{ab})=\{\mathsf{EXISTENCE(c), INIT(b)}\}.$$

In this simple case, the subsets satisfying the condition of Line \ref{alg:subsetS} in Algorithm \ref{alg:select} would be: 
\begin{align*}
 S_1= &  \{\mathsf{EXISTENCE(c)}\}  \\
 S_2= &  \{\mathsf{INIT(b)}\}   \\
 S_3= &  \{\mathsf{EXISTENCE(c)}, \mathsf{INIT(b)}\} \\
 S_4= & \{\mathsf{EXISTENCE(c)}, \mathsf{EXISTENCE(a)}\} \\
  ... & \\
 S_n= & \{\mathsf{EXISTENCE(c)}, \mathsf{INIT(b)}, \mathsf{EXISTENCE(a)}\} \\
 ... &
\end{align*}

As we are interested in the most general models, both $S_1=$ $\{\ \mathsf{EXISTENCE(c)}\ \}$ and $S_2=\{\ \mathsf{INIT(b)}\ \}$ are optimal solutions. Note that these two solutions cannot be compared according to the definitions of generality because there exist traces (such as the unknown trace $\mathsf{b}$) compliant with $S_2$ and non-compliant with $S_1$ (i.e., there is no subset relation between ${C}_{S_1}$ and ${C}_{S_2}$).
Obviously, the choice of one model over another influences the classification of all those unknown traces that---being not part of the input log---are not labelled as positive of negative.

If we were interested in the most simple solution instead, $S_1=\{\ \mathsf{EXISTENCE(c)}\ \}$ would have been our choice, because its closure is the smaller in cardinality.

Finally, if we were interested in the most specific set of constraints, the application of a convenient ${is\_better}$ function would have determined the choice of $\{\mathsf{EXISTENCE(a)}$, $\mathsf{EXISTENCE(c)}$, $\mathsf{INIT(b)}\}$---where the redundancy check of Eq. \eqref{eq:redun} operated by discarding $\mathsf{EXISTENCE(b)}$. 
\end{example}

%
%Algorithm \ref{alg:select} easily computes the set $C$ of all constraints excluding at least one negate traces as $C=$$\{ \textsf{EXISTENCE(c)}$, $\textsf{INIT(b)}\}$. In this simple case, the subsets of $C$ satisfying the first condition (Line \ref{alg:select:1} of Algorithm \ref{alg:select}) are: $\{\textsf{EXISTENCE(c)}\}$, $\{\textsf{INIT(b)}\}$, and $\{\textsf{EXISTENCE(c)}$,$\textsf{INIT(b)}\}$. As we are interested in the most general model, both the solutions $S=$$\{\textsf{EXISTENCE(c)}\}$ and $S=$$\{\textsf{INIT(b)}\}$ are valid. Note that 
%

%

%
%According to this model, the trace \textsf{b} is negative and \textsf{bca} is positive. 


%
%\tcolor{blue}{**************************}
%
%Therefore, the algorithm is guided by the following schema:
%\begin{outline}
%\1 let the set of constraints ${compatibles}= \{c \in D[A] | \forall t \in L^+ \models c\}$;
%\1 let the function ${choices} : L^- \rightarrow 2^{D[A]}$ be such that ${choices}(t) = \{c \in {compatibles} | t \not\models c\}$;
%\1 search the sets $S \subseteq {compatibles}$ such that both the following conditions are satisfied:
%	\2 $\forall t \in L^-, {choices}(t) \cap {cl}(S \cup P) \neq \varnothing$;
%	\2 $S$ is minimal in the sense that there is no $S'$ such that $ {cl}(S' \cup P) \subset {cl}(S \cup P)$
%\end{outline}
%
%Clearly, any set generated by the algorithm satisfies the conditions 1 and 2 above but it might not be minimal. The requirement of minimality is guided by our need to determine the most general set of constraints.
%However, we also need to guarantee that no solution is missed, i.e., all possible solutions are included in at least one of the sets generated by the algorithm. The advantage of our proposal is that it can be implemented using off-the-shelves optimisation tools (as shown in the section below), where---adapting the closure operator and the optimisation conditions---we can easily experiment with different model fitness functions.
%
%Per ridurre ulteriormente il numero di S in output (oppure per ordinare le soluzioni trovate) potremmo contare gli elementi della closure. oppure puo` essere una preferenza tra template


